# -*- coding: utf-8 -*-
"""Benchmark building EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rq6oHrks57UxFwFFFvR34rtOzhrKk6Uv
"""

from google.colab import drive
drive.mount('/content/drive')

base_path = "/content/drive/MyDrive/IDEAL"

import pandas as pd
import numpy as np
import glob
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('seaborn-v0_8-whitegrid')

# Detect all home files
home_files = glob.glob(f"{base_path}/home*_clean=*.csv")
print(f"✅ Found {len(home_files)} home files.")
home_files[:5]

df_weather = pd.read_csv(f"{base_path}/weather_era5.csv")
df_weather.columns = df_weather.columns.str.lower()
df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])
df_weather = df_weather.sort_values('timestamp').set_index('timestamp')

print("✅ ERA5 weather shape:", df_weather.shape)
print("Columns:", list(df_weather.columns))
df_weather.head(3)

dfs = []

for f in home_files:
    fname = f.split('/')[-1]
    home_id = fname.split('_')[0]               # e.g. home47
    year = int(fname.split('=')[-1].replace('.csv',''))  # e.g. 2016

    df = pd.read_csv(f)
    df.columns = df.columns.str.lower()

    # Fix timestamp column name if saved as index
    if 'unnamed: 0' in df.columns:
        df = df.rename(columns={'unnamed: 0': 'timestamp'})

    # Parse and set timestamp
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values('timestamp').set_index('timestamp')

    # Merge with weather
    df = df.join(df_weather, how='left', rsuffix='_w')

    # Add metadata
    df['home'] = home_id
    df['year'] = year

    dfs.append(df)

df_all = pd.concat(dfs, ignore_index=False)
print("✅ Combined dataset:", df_all.shape)
df_all.head(3)



df_all['hour'] = df_all.index.hour
df_all['month'] = df_all.index.month
df_all['dayofweek'] = df_all.index.dayofweek
df_all['date'] = df_all.index.date

print("Homes:", df_all['home'].unique())
print("Years:", sorted(df_all['year'].unique()))
print("Columns:", df_all.columns.tolist())

# Check for missing timestamps
missing_by_home = df_all.groupby('home').apply(lambda x: x.index.duplicated().sum())
print("\nDuplicate timestamps per home:\n", missing_by_home)

# === Aggregate Trend ===
agg = df_all.groupby('timestamp')['power'].agg(['mean','std'])
plt.figure(figsize=(10,4))
plt.plot(agg.index, agg['mean'], color='steelblue', label='Mean Power')
plt.fill_between(
    agg.index,
    agg['mean'] - agg['std'],
    agg['mean'] + agg['std'],
    color='skyblue', alpha=0.3, label='±1 SD'
)
plt.title('Aggregate Hourly Power Across All Homes')
plt.xlabel('Timestamp')
plt.ylabel('Power (kW)')
plt.legend()
plt.tight_layout()
plt.show()

# === Average Diurnal Pattern ===
hourly_pattern = df_all.groupby('hour')['power'].mean().reset_index()
plt.figure(figsize=(8,4))
sns.lineplot(data=hourly_pattern, x='hour', y='power', color='teal', lw=2)
plt.title('Average Hourly Load Pattern (All Homes)')
plt.xlabel('Hour of Day')
plt.ylabel('Average Power (kW)')
plt.xticks(range(0,24))
plt.tight_layout()
plt.show()

series = df_all.groupby('timestamp')['power'].mean().resample('H').mean()
print(series.index.min(), '→', series.index.max(), '|', series.size, 'points')

import numpy as np
from math import sqrt

def lag_compare(s, lag):
    s_shift = s.shift(lag)
    valid = s.dropna().index.intersection(s_shift.dropna().index)
    a, b = s.loc[valid], s_shift.loc[valid]
    rmse = sqrt(np.mean((a - b)**2))
    corr = np.corrcoef(a, b)[0,1]
    return {'lag_hours': lag, 'rmse': rmse, 'corr': corr}

lags = [24, 48, 72, 96, 120, 144, 168]
results = pd.DataFrame([lag_compare(series, L) for L in lags])
print(results)

best = results.loc[results['rmse'].idxmin(), 'lag_hours']

plt.figure(figsize=(10,4))
series.plot(label='Original', alpha=0.7)
series.shift(best).plot(label=f'Shifted {best}h', alpha=0.7)
plt.legend()
plt.title(f'Original vs {best}-Hour Shifted Power Series')
plt.xlabel('Timestamp'); plt.ylabel('Mean Power (kW)')
plt.tight_layout(); plt.show()

monthly_consistent = (
    df_all.groupby(['home', pd.Grouper(freq='M')])['power']
          .mean()
          .groupby(level=1)
          .mean()
)
plt.figure(figsize=(8,4))
monthly_consistent.plot(marker='o', color='steelblue')
plt.title('Per-Home Average Monthly Load')
plt.ylabel('Power (kW)')
plt.tight_layout(); plt.show()

"""Outlier Analysis"""

def detect_home_outliers_iqr(x, iqr_factor=3):
    q1, q3 = x.quantile([0.25, 0.75])
    iqr = q3 - q1
    lower, upper = q1 - iqr_factor*iqr, q3 + iqr_factor*iqr
    return (x < lower) | (x > upper)

# ✅ transform keeps same index, no reindex issues
df_all['is_outlier'] = (
    df_all.groupby('home')['power']
          .transform(detect_home_outliers_iqr)
)

outlier_summary = (
    df_all.groupby('home')['is_outlier']
          .mean()
          .sort_values(ascending=False)
          .to_frame('outlier_rate')
)
outlier_summary.head(10)

plt.figure(figsize=(6,6))
sns.histplot(outlier_summary['outlier_rate'], bins=30, color='teal')
plt.title('Distribution of Outlier Rates Across Homes')
plt.xlabel('Fraction of Hours Flagged as Outliers')
plt.ylabel('Count of Homes')
plt.tight_layout(); plt.show()

top_outliers = outlier_summary.head(5).index.tolist()

fig, axes = plt.subplots(len(top_outliers), 1, figsize=(10, 6), sharex=True)
for i, home in enumerate(top_outliers):
    temp = df_all[df_all['home'] == home]
    axes[i].plot(temp.index, temp['power'], color='steelblue', alpha=0.7)
    axes[i].scatter(temp[temp['is_outlier']].index, temp[temp['is_outlier']]['power'],
                    color='red', s=8)
    axes[i].set_title(f"{home} (outlier rate: {temp['is_outlier'].mean():.2%})")
plt.tight_layout(); plt.show()

def rolling_outlier_flags(series, window=24*7, z_thresh=3):
    roll_mean = series.rolling(window, center=True, min_periods=24).mean()
    roll_std  = series.rolling(window, center=True, min_periods=24).std()
    z = (series - roll_mean) / roll_std
    return np.abs(z) > z_thresh

df_all['is_context_outlier'] = (
    df_all.groupby('home')['power']
          .transform(lambda s: rolling_outlier_flags(s))
)

context_summary = (
    df_all.groupby('home')['is_context_outlier']
          .mean()
          .sort_values(ascending=False)
)
sns.boxplot(x=context_summary, color='lightcoral')
plt.title('Per-Home Contextual Outlier Rates')
plt.xlabel('Fraction of Hours Flagged')
plt.tight_layout(); plt.show()

